{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a464d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "# matplotlib complains about the behaviour of librosa.display, so we'll ignore those warnings:\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236dc052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(file):\n",
    "    X, sample_rate = librosa.load(file, 48000)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),sr=sample_rate).T,axis=0)\n",
    "    \n",
    "    feature_matrix=np.array([])\n",
    "    feature_matrix = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "        \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path):\n",
    "    return get_features(path)\n",
    "\n",
    "def label_to_id(label):\n",
    "    label_list = ['Neutral', 'Calm', 'Happy', 'Sad', 'Angry', 'Fear', 'Disgust', 'Surprise']\n",
    "\n",
    "    if len(label_list) > 0:\n",
    "        return label_list.index(label) if label in label_list else -1\n",
    "\n",
    "    return label\n",
    "\n",
    "def preprocess_function(examples, input_column = \"path\", output_column = \"emotion\"):\n",
    "    \"\"\"\n",
    "    Load the recordings with their labels.\n",
    "    :param examples:[DataFrame]  with the samples of the training or test sets.\n",
    "    :param input_column:[str]  Column that contain the paths to the recordings\n",
    "    :param output_column:[str]  Column that contain the emotion associated to each recording\n",
    "    :param target_sampling_rate:[int] Global variable with the expected sampling rate of the model\n",
    "    \"\"\"\n",
    "    speech_list = [speech_file_to_array_fn(path) for path in tqdm(examples[input_column])]\n",
    "    target_list = [label_to_id(label) for label in examples[output_column]]\n",
    "\n",
    "    result = {\n",
    "        'input_values': speech_list,\n",
    "        'labels': target_list\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "save_dir = 'via_bagustris'\n",
    "\n",
    "dataset_1d = []\n",
    "for fold in range(5):\n",
    "    save_path = os.path.join('audio_48k', \"fold\"+str(fold))\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    data_files = {\n",
    "        \"train\": os.path.join(save_path, \"train.csv\"),\n",
    "        \"validation\": os.path.join(save_path, \"test.csv\"),\n",
    "    }\n",
    "    \n",
    "    #Load data\n",
    "    dataset = load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\", )\n",
    "    train_dataset = dataset[\"train\"]\n",
    "    eval_dataset = dataset[\"validation\"]\n",
    "    \n",
    "    train = preprocess_function(train_dataset)\n",
    "    test = preprocess_function(eval_dataset)\n",
    "    \n",
    "    X_train = np.array(train[\"input_values\"])\n",
    "    y_train = np.array(train['labels'])\n",
    "    X_test = np.array(test[\"input_values\"])\n",
    "    y_test = np.array(test['labels'])\n",
    "    \n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    \n",
    "    numpy_name = os.path.join(save_dir, str(fold) + '.npy')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    with open(numpy_name, 'wb') as f:\n",
    "        np.save(f, X_train)\n",
    "        np.save(f, y_train)\n",
    "        np.save(f, X_test)\n",
    "        np.save(f, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a2a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential  \n",
    "from tensorflow.keras.layers import Dense, Activation, GRU, Flatten, LSTM, Flatten \n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Bidirectional\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "np.random.seed(123)\n",
    "rn.seed(123)\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03cefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_dim, n_classes):  \n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(axis=-1, input_shape=(1, 193)))\n",
    "    model.add(LSTM(n_dim, return_sequences=True, dropout=0.1,recurrent_dropout=0.2))  \n",
    "    model.add(LSTM(n_dim*2, dropout=0.1, recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(LSTM(n_dim, dropout=0.1, recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "              \n",
    "    # model compilation  \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18834314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):  \n",
    "    n_labels = len(labels)  \n",
    "    n_unique_labels = len(np.unique(labels))  \n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels+1))  \n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1  \n",
    "    one_hot_encode=np.delete(one_hot_encode, 0, axis=1)  \n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c718320",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "npy_path = 'via_bagustris'\n",
    "all_npy = os.listdir(npy_path)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_acc', mode='max', patience=100, restore_best_weights=True)\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "for fold in all_npy:\n",
    "    npy = os.path.join(npy_path, fold)\n",
    "    \n",
    "    with open(npy, 'rb') as f:\n",
    "        X_train = np.load(f)\n",
    "        y_train = np.load(f)\n",
    "        X_test = np.load(f)\n",
    "        y_test = np.load(f)\n",
    "    \n",
    "    X_train = np.expand_dims(X_train, axis=1)\n",
    "    X_test = np.expand_dims(X_test, axis=1)\n",
    "    y_train = one_hot_encode(y_train)\n",
    "    y_test = one_hot_encode(y_test)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    model = create_model(X_train.shape[2], y_train.shape[1])\n",
    "    print(model.summary())\n",
    "    \n",
    "    hist = model.fit(x=X_train, y=y_train, epochs=500, batch_size=64, \n",
    "                 validation_data=[X_test, y_test], callbacks=[earlystop])\n",
    "    \n",
    "    print(max(hist.history['accuracy']), max(hist.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461209c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
