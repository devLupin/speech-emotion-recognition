{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969eda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from natsort import natsorted\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff36aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_RAVDESS_DS(path_audios):\n",
    "    \"\"\"\n",
    "    Generation of the dataframe with the information of the dataset. The dataframe has the following structure:\n",
    "     ______________________________________________________________________________________________________________________________\n",
    "    |             name            |                     path                                   |     emotion      |     actor     |\n",
    "    ______________________________________________________________________________________________________________________________\n",
    "    |  01-01-01-01-01-01-01.wav   |    <RAVDESS_dir>/audios_16kHz/01-01-01-01-01-01-01.wav     |     Neutral      |     1         |\n",
    "    ______________________________________________________________________________________________________________________________\n",
    "    ...\n",
    "    :param path_audios: Path to the folder that contains all the audios in .wav format, 16kHz and single-channel(mono)\n",
    "    \"\"\"\n",
    "    dict_emotions = {\n",
    "        0: 'Neutral',\n",
    "        1: 'Calm',\n",
    "        2: 'Happy',\n",
    "        3: 'Sad',\n",
    "        4: 'Angry',\n",
    "        5: 'Fear',\n",
    "        6: 'Disgust',\n",
    "        7: 'Surprise'\n",
    "    }\n",
    "    \n",
    "    wav_paths, emotions, names = [], [], []\n",
    "    for path in tqdm(Path(path_audios).glob(\"*/*.wav\")):\n",
    "        name = str(path).split('/')[-1].split('.')[0]\n",
    "        actor = int(name.split(\"-\")[-1])\n",
    "        label = int(name.split(\"-\")[2]) - 1  # Start emotions in 0\n",
    "\n",
    "        try:\n",
    "            wav_paths.append(path)\n",
    "            emotions.append(label)\n",
    "            names.append(actor)\n",
    "        except Exception as e:\n",
    "            # print(str(path), e)\n",
    "            pass\n",
    "        \n",
    "    return wav_paths, emotions, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0710258c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1440it [00:00, 43288.90it/s]\n"
     ]
    }
   ],
   "source": [
    "paths, emotions, actors = prepare_RAVDESS_DS('only_speech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48dc2e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = []\n",
    "\n",
    "def save_melspectrogram(paths, emotions, actors):\n",
    "    data = []\n",
    "    for i, path in tqdm(enumerate(paths), desc='melspectrogram image generate.....'):\n",
    "        print(path)\n",
    "        y, sr = librosa.load(path, sr=16000)\n",
    "        \n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, win_length=512, window='hamming', hop_length=256, n_mels=256, fmax=sr/2)\n",
    "        melspectrogram = librosa.power_to_db(S, ref=np.max)\n",
    "        \n",
    "        size.append(melspectrogram.shape[1])\n",
    "        \n",
    "        temp = np.zeros((256, 562))\n",
    "        temp[:,:melspectrogram.shape[1]] = melspectrogram\n",
    "        \n",
    "        data.append({\n",
    "            'melspectrogram_feature': temp,\n",
    "            'emotion': emotions[i],\n",
    "            'actor': actors[i]\n",
    "        })\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad28911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 4it [00:00, 32.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_01\\03-01-01-01-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-01-01-01-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-01-01-02-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-01-01-02-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-02-01-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-02-01-01-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-02-01-02-01-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 12it [00:00, 29.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_01\\03-01-02-01-02-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-02-02-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-02-02-01-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-02-02-02-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-02-02-02-02-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 16it [00:00, 30.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_01\\03-01-03-01-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-03-01-01-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-03-01-02-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-03-01-02-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-03-02-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-03-02-01-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-03-02-02-01-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 24it [00:00, 31.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_01\\03-01-03-02-02-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-04-01-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-04-01-01-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-04-01-02-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-04-01-02-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-04-02-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-04-02-01-02-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 32it [00:01, 30.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_01\\03-01-04-02-02-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-04-02-02-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-05-01-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-05-01-01-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-05-01-02-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-05-01-02-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-05-02-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-05-02-01-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-05-02-02-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-05-02-02-02-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 40it [00:01, 27.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_01\\03-01-06-01-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-06-01-01-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-06-01-02-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-06-01-02-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-06-02-01-01-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 43it [00:01, 24.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_01\\03-01-06-02-01-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-06-02-02-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-06-02-02-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-07-01-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-07-01-01-02-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 49it [00:01, 23.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_01\\03-01-07-01-02-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-07-01-02-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-07-02-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-07-02-01-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-07-02-02-01-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 56it [00:02, 27.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_01\\03-01-07-02-02-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-08-01-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-08-01-01-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-08-01-02-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-08-01-02-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-08-02-01-01-01.wav\n",
      "only_speech\\Actor_01\\03-01-08-02-01-02-01.wav\n",
      "only_speech\\Actor_01\\03-01-08-02-02-01-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 64it [00:02, 31.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_01\\03-01-08-02-02-02-01.wav\n",
      "only_speech\\Actor_02\\03-01-01-01-01-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-01-01-01-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-01-01-02-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-01-01-02-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-02-01-01-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-02-01-01-02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 68it [00:02, 30.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_02\\03-01-02-01-02-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-02-01-02-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-02-02-01-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-02-02-01-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-02-02-02-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-02-02-02-02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 76it [00:02, 29.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_02\\03-01-03-01-01-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-03-01-01-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-03-01-02-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-03-01-02-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-03-02-01-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-03-02-01-02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 80it [00:02, 29.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_02\\03-01-03-02-02-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-03-02-02-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-04-01-01-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-04-01-01-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-04-01-02-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-04-01-02-02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 88it [00:03, 30.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_02\\03-01-04-02-01-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-04-02-01-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-04-02-02-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-04-02-02-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-05-01-01-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-05-01-01-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-05-01-02-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 96it [00:03, 30.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_02\\03-01-05-01-02-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-05-02-01-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-05-02-01-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-05-02-02-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-05-02-02-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-06-01-01-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 100it [00:03, 28.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_speech\\Actor_02\\03-01-06-01-01-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-06-01-02-01-02.wav\n",
      "only_speech\\Actor_02\\03-01-06-01-02-02-02.wav\n",
      "only_speech\\Actor_02\\03-01-06-02-01-01-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input signal length=0 is too small to resample from 48000->16000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m save_melspectrogram(paths, emotions, actors)\n\u001b[0;32m      2\u001b[0m \u001b[39mmax\u001b[39m(size)\n",
      "Cell \u001b[1;32mIn [9], line 7\u001b[0m, in \u001b[0;36msave_melspectrogram\u001b[1;34m(paths, emotions, actors)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i, path \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(paths), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmelspectrogram image generate.....\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(path)\n\u001b[1;32m----> 7\u001b[0m     y, sr \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(path, sr\u001b[39m=\u001b[39;49m\u001b[39m16000\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m     S \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mfeature\u001b[39m.\u001b[39mmelspectrogram(y\u001b[39m=\u001b[39my, sr\u001b[39m=\u001b[39msr, n_fft\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m, win_length\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, window\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhamming\u001b[39m\u001b[39m'\u001b[39m, hop_length\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, n_mels\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, fmax\u001b[39m=\u001b[39msr\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     10\u001b[0m     melspectrogram \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mpower_to_db(S, ref\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mmax)\n",
      "File \u001b[1;32mc:\\Users\\devLupin\\Miniconda3\\envs\\ser\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\devLupin\\Miniconda3\\envs\\ser\\lib\\site-packages\\librosa\\core\\audio.py:179\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    176\u001b[0m     y \u001b[39m=\u001b[39m to_mono(y)\n\u001b[0;32m    178\u001b[0m \u001b[39mif\u001b[39;00m sr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     y \u001b[39m=\u001b[39m resample(y, orig_sr\u001b[39m=\u001b[39;49msr_native, target_sr\u001b[39m=\u001b[39;49msr, res_type\u001b[39m=\u001b[39;49mres_type)\n\u001b[0;32m    181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     sr \u001b[39m=\u001b[39m sr_native\n",
      "File \u001b[1;32mc:\\Users\\devLupin\\Miniconda3\\envs\\ser\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\devLupin\\Miniconda3\\envs\\ser\\lib\\site-packages\\librosa\\core\\audio.py:647\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    645\u001b[0m     y_hat \u001b[39m=\u001b[39m soxr\u001b[39m.\u001b[39mresample(y\u001b[39m.\u001b[39mT, orig_sr, target_sr, quality\u001b[39m=\u001b[39mres_type)\u001b[39m.\u001b[39mT\n\u001b[0;32m    646\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 647\u001b[0m     y_hat \u001b[39m=\u001b[39m resampy\u001b[39m.\u001b[39;49mresample(y, orig_sr, target_sr, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49mres_type, axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m fix:\n\u001b[0;32m    650\u001b[0m     y_hat \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mfix_length(y_hat, size\u001b[39m=\u001b[39mn_samples, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\devLupin\\Miniconda3\\envs\\ser\\lib\\site-packages\\resampy\\core.py:117\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, parallel, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m shape[axis] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(shape[axis] \u001b[39m*\u001b[39m \u001b[39mfloat\u001b[39m(sr_new) \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(sr_orig))\n\u001b[0;32m    116\u001b[0m \u001b[39mif\u001b[39;00m shape[axis] \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    118\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mInput signal length=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is too small to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresample from \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m->\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(x\u001b[39m.\u001b[39mshape[axis], sr_orig, sr_new)\n\u001b[0;32m    120\u001b[0m     )\n\u001b[0;32m    122\u001b[0m \u001b[39m# Preserve contiguity of input (if it exists)\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(x\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger):\n",
      "\u001b[1;31mValueError\u001b[0m: Input signal length=0 is too small to resample from 48000->16000"
     ]
    }
   ],
   "source": [
    "save_melspectrogram(paths, emotions, actors)\n",
    "max(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b31907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 535it [00:02, 236.00it/s]\n"
     ]
    }
   ],
   "source": [
    "df = save_melspectrogram(paths, emotions, actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8b15c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.functional import compute_deltas\n",
    "import torch\n",
    "\n",
    "def get_deltas(feature):\n",
    "    f = np.expand_dims(feature, 1)\n",
    "    f = torch.Tensor(f)\n",
    "    \n",
    "    delta = compute_deltas(f)\n",
    "    delta2 = compute_deltas(delta)\n",
    "    \n",
    "    ret = torch.cat([f, delta, delta2], dim=1)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b75f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test(fold, df, save_path=\"\"):\n",
    "    \"\"\"\n",
    "    Divide the data in train and test in a subject-wise 5-CV way. The division is generated before running the training\n",
    "    of each fold.\n",
    "    :param fold:[int] Fold to create the train and test sets [ranging from 0 - 4]\n",
    "    :param df:[DataFrame] Dataframe with the complete list of files generated\n",
    "    :param save_path:[str] Path to save the train.csv and test.csv per fold\n",
    "    \"\"\"\n",
    "    \n",
    "    actors_per_fold = {\n",
    "        0: [2,5,14,15,16],\n",
    "        1: [3, 6, 7, 13, 18],\n",
    "        2: [10, 11, 12, 19, 20],\n",
    "        3: [8, 17, 21, 23, 24],\n",
    "        4: [1, 4, 9, 22],\n",
    "    }\n",
    "\n",
    "    test_df = df.loc[df['actor'].isin(actors_per_fold[fold])]\n",
    "    train_df = df.loc[~df['actor'].isin(actors_per_fold[fold])]\n",
    "\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    \n",
    "    X_train = np.array([data for data in train_df['melspectrogram_feature']])\n",
    "    y_train = np.array([data for data in train_df['emotion']])\n",
    "    X_test = np.array([data for data in test_df['melspectrogram_feature']])\n",
    "    y_test = np.array([data for data in test_df['emotion']])\n",
    "    \n",
    "    X_train = get_deltas(X_train)\n",
    "    X_test = get_deltas(X_test)\n",
    "    \n",
    "    with open(save_path+'.npy', 'wb') as f:\n",
    "        np.save(f, X_train)\n",
    "        np.save(f, y_train)\n",
    "        np.save(f, X_test)\n",
    "        np.save(f, y_test)\n",
    "        \n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1ce940d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([428, 3, 256, 562]) (428,) torch.Size([107, 3, 256, 562]) (107,)\n",
      "torch.Size([454, 3, 256, 562]) (454,) torch.Size([81, 3, 256, 562]) (81,)\n",
      "torch.Size([445, 3, 256, 562]) (445,) torch.Size([90, 3, 256, 562]) (90,)\n",
      "torch.Size([405, 3, 256, 562]) (405,) torch.Size([130, 3, 256, 562]) (130,)\n",
      "torch.Size([408, 3, 256, 562]) (408,) torch.Size([127, 3, 256, 562]) (127,)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for fold in range(5):\n",
    "    \n",
    "    save_path = os.path.join('5-CV-only-speech', \"fold\"+str(fold))\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    generate_train_test(fold, df, save_path)\n",
    "    time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5be54bb8ddc52e76cc18bd1012223019b9a180863a571d33caf1c2c34a734fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
