{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969eda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from natsort import natsorted\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff36aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_RAVDESS_DS(path_audios):\n",
    "    wav_paths, emotions, actors = [], [], []\n",
    "    for path in tqdm(Path(path_audios).glob(\"*/*.wav\")):\n",
    "        name = str(path).split('/')[-1].split('.')[0]\n",
    "        label = int(name.split(\"-\")[2]) - 1  # Start emotions in 0\n",
    "        actor = int(name.split(\"-\")[-1])\n",
    "\n",
    "        try:\n",
    "            wav_paths.append(path)\n",
    "            emotions.append(label)\n",
    "            actors.append(actor)\n",
    "        except Exception as e:\n",
    "            # print(str(path), e)\n",
    "            pass\n",
    "        \n",
    "    return wav_paths, emotions, actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48dc2e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_melspectrogram(paths, emotions, actors):\n",
    "    data = []\n",
    "    for i, path in tqdm(enumerate(paths), desc='melspectrogram image generate.....'):\n",
    "        y, sr = librosa.load(path, sr=16000)\n",
    "        \n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, win_length=512, window='hamming', hop_length=256, n_mels=256, fmax=sr/2)\n",
    "        melspectrogram = librosa.power_to_db(S, ref=np.max)\n",
    "        \n",
    "        temp = np.zeros((256, 307))\n",
    "        temp[:,:melspectrogram.shape[1]] = melspectrogram\n",
    "        \n",
    "        data.append({\n",
    "            'melspectrogram_feature': temp,\n",
    "            'emotion': emotions[i],\n",
    "            'actor': actors[i]\n",
    "        })\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b31907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 1440it [01:02, 23.01it/s]\n"
     ]
    }
   ],
   "source": [
    "df = save_melspectrogram(paths, emotions, actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8b15c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.functional import compute_deltas\n",
    "import torch\n",
    "\n",
    "def get_deltas(feature):\n",
    "    f = np.expand_dims(feature, 1)\n",
    "    f = torch.Tensor(f)\n",
    "    \n",
    "    delta = compute_deltas(f)\n",
    "    delta2 = compute_deltas(delta)\n",
    "    \n",
    "    ret = torch.cat([f, delta, delta2], dim=1)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b75f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test(fold, df, save_path=\"\"):\n",
    "    \"\"\"\n",
    "    Divide the data in train and test in a subject-wise 5-CV way. The division is generated before running the training\n",
    "    of each fold.\n",
    "    :param fold:[int] Fold to create the train and test sets [ranging from 0 - 4]\n",
    "    :param df:[DataFrame] Dataframe with the complete list of files generated\n",
    "    :param save_path:[str] Path to save the train.csv and test.csv per fold\n",
    "    \"\"\"\n",
    "    \n",
    "    actors_per_fold = {\n",
    "        0: [2,5,14,15,16],\n",
    "        1: [3, 6, 7, 13, 18],\n",
    "        2: [10, 11, 12, 19, 20],\n",
    "        3: [8, 17, 21, 23, 24],\n",
    "        4: [1, 4, 9, 22],\n",
    "    }\n",
    "\n",
    "    test_df = df.loc[df['actor'].isin(actors_per_fold[fold])]\n",
    "    train_df = df.loc[~df['actor'].isin(actors_per_fold[fold])]\n",
    "\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    \n",
    "    X_train = np.array([data for data in train_df['melspectrogram_feature']])\n",
    "    y_train = np.array([data for data in train_df['emotion']])\n",
    "    X_test = np.array([data for data in test_df['melspectrogram_feature']])\n",
    "    y_test = np.array([data for data in test_df['emotion']])\n",
    "    \n",
    "    X_train = get_deltas(features_train)\n",
    "    X_test = get_deltas(features_test)\n",
    "    \n",
    "    with open(save_path+'.npy', 'wb') as f:\n",
    "        np.save(f, X_train)\n",
    "        np.save(f, y_train)\n",
    "        np.save(f, X_test)\n",
    "        np.save(f, y_test)\n",
    "        \n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1ce940d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (256,307) (2,256) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5-CV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(fold))\n\u001b[0;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mgenerate_train_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn [10], line 30\u001b[0m, in \u001b[0;36mgenerate_train_test\u001b[1;34m(fold, df, save_path)\u001b[0m\n\u001b[0;32m     27\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([data \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     29\u001b[0m train, test \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m---> 30\u001b[0m features_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43maugment_awgn_waveforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m48000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m features_test, y_test \u001b[38;5;241m=\u001b[39m augment_awgn_waveforms(X_test, test, y_test, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m48000\u001b[39m)\n\u001b[0;32m     33\u001b[0m X_train \u001b[38;5;241m=\u001b[39m get_deltas(features_train)\n",
      "Cell \u001b[1;32mIn [7], line 47\u001b[0m, in \u001b[0;36maugment_awgn_waveforms\u001b[1;34m(waveforms, features, emotions, multiples, sample_rate)\u001b[0m\n\u001b[0;32m     42\u001b[0m emotions \u001b[38;5;241m=\u001b[39m emotions\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m waveform \u001b[38;5;129;01min\u001b[39;00m waveforms:\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# Generate 2 augmented multiples of the dataset, i.e. 1440 native + 1440*2 noisy = 4320 samples total\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     augmented_waveforms \u001b[38;5;241m=\u001b[39m \u001b[43mawgn_waveforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultiples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# compute spectrogram for each of 2 augmented waveforms\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m augmented_waveform \u001b[38;5;129;01min\u001b[39;00m augmented_waveforms:\n\u001b[0;32m     51\u001b[0m \n\u001b[0;32m     52\u001b[0m         \u001b[38;5;66;03m# Compute MFCCs over augmented waveforms\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [7], line 32\u001b[0m, in \u001b[0;36mawgn_waveforms\u001b[1;34m(waveform, multiples, bits, snr_min, snr_max)\u001b[0m\n\u001b[0;32m     28\u001b[0m covariance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((wave_len, multiples)) \u001b[38;5;241m*\u001b[39m covariance\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Since covariance and noise are arrays, * is the haddamard product\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Take Haddamard product of covariance and noise to generate white noise\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m multiple_augmented_waveforms \u001b[38;5;241m=\u001b[39m \u001b[43mwaveform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcovariance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m multiple_augmented_waveforms\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (256,307) (2,256) "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for fold in range(5):\n",
    "    \n",
    "    save_path = os.path.join('5-CV', \"fold\"+str(fold))\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    generate_train_test(fold, df, save_path)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21536b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5be54bb8ddc52e76cc18bd1012223019b9a180863a571d33caf1c2c34a734fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
