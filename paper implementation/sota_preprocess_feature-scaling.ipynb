{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e78e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devLupin\\miniconda3\\envs\\ser\\lib\\site-packages\\torchaudio\\extension\\extension.py:13: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['LC_ALL'] ='C.UTF-8'\n",
    "os.environ['LANG'] = 'C.UTF-8'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acfcbb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display\n",
    "\n",
    "def get_waveforms(file, sample_rate=16000):\n",
    "    \n",
    "    # load an individual sample audio file\n",
    "    # read the full 3 seconds of the file, cut off the first 0.5s of silence; native sample rate = 48k\n",
    "    # don't need to store the sample rate that librosa.load returns\n",
    "    waveform, _ = librosa.load(file, duration=3, offset=0.5, sr=sample_rate)\n",
    "    \n",
    "    # make sure waveform vectors are homogenous by defining explicitly\n",
    "    waveform_homo = np.zeros((int(sample_rate*3,)))\n",
    "    waveform_homo[:len(waveform)] = waveform\n",
    "    \n",
    "    # return a single file's waveform                                      \n",
    "    return waveform_homo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e3fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, emotion):\n",
    "    waveforms, emotions = [], []\n",
    "    for p in path:\n",
    "        waveforms.append(get_waveforms(p))\n",
    "    for e in emotion:\n",
    "        emotions.append(e)\n",
    "    \n",
    "    return waveforms, emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c739d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_mfcc(\n",
    "    waveform, \n",
    "    sample_rate,\n",
    "    n_mfcc = 40,\n",
    "    fft = 1024,\n",
    "    winlen = 512,\n",
    "    window='hamming',\n",
    "    #hop=256, # increases # of time steps; was not helpful\n",
    "    mels=128\n",
    "    ):\n",
    "\n",
    "    # Compute the MFCCs for all STFT frames \n",
    "    # 40 mel filterbanks (n_mfcc) = 40 coefficients\n",
    "    mfc_coefficients=librosa.feature.mfcc(\n",
    "        y=waveform, \n",
    "        sr=sample_rate, \n",
    "        n_mfcc=n_mfcc,\n",
    "        n_fft=fft, \n",
    "        win_length=winlen, \n",
    "        window=window, \n",
    "        #hop_length=hop, \n",
    "        n_mels=mels, \n",
    "        fmax=sample_rate/2\n",
    "        ) \n",
    "\n",
    "    return mfc_coefficients\n",
    "\n",
    "def get_features(waveforms, sample_rate=16000):\n",
    "    features = []\n",
    "    \n",
    "    # initialize counter to track progress\n",
    "    file_count = 0\n",
    "\n",
    "    # process each waveform individually to get its MFCCs\n",
    "    for waveform in waveforms:\n",
    "        mfccs = feature_mfcc(waveform, sample_rate)\n",
    "        features.append(mfccs)\n",
    "        file_count += 1\n",
    "        # print progress \n",
    "        print('\\r'+f' Processed {file_count}/{len(waveforms)} waveforms',end='')\n",
    "    \n",
    "    # return all features from list of waveforms\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f515a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def feature_scaling(X_train, X_test, y_train, y_test):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #### Scale the training data ####\n",
    "    # store shape so we can transform it back \n",
    "    N,C,H,W = X_train.shape\n",
    "    # Reshape to 1D because StandardScaler operates on a 1D array\n",
    "    # tell numpy to infer shape of 1D array with '-1' argument\n",
    "    X_train = np.reshape(X_train, (N,-1)) \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    # Transform back to NxCxHxW 4D tensor format\n",
    "    X_train = np.reshape(X_train, (N,C,H,W))\n",
    "\n",
    "    #### Scale the test set ####\n",
    "    N,C,H,W = X_test.shape\n",
    "    X_test = np.reshape(X_test, (N,-1))\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_test = np.reshape(X_test, (N,C,H,W))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ffa834e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processed 600/600 waveformsmsX_train scaled:(2280, 1, 40, 98), y_train:(2280,)\n",
      "X_test scaled:(600, 1, 40, 98), y_test:(600,)\n",
      "\n",
      "saved to via_wav2vec_preprocess\\0.npy\n",
      " Processed 600/600 waveformsmsX_train scaled:(2280, 1, 40, 98), y_train:(2280,)\n",
      "X_test scaled:(600, 1, 40, 98), y_test:(600,)\n",
      "\n",
      "saved to via_wav2vec_preprocess\\1.npy\n",
      " Processed 600/600 waveformsmsX_train scaled:(2280, 1, 40, 98), y_train:(2280,)\n",
      "X_test scaled:(600, 1, 40, 98), y_test:(600,)\n",
      "\n",
      "saved to via_wav2vec_preprocess\\2.npy\n",
      " Processed 600/600 waveformsmsX_train scaled:(2280, 1, 40, 98), y_train:(2280,)\n",
      "X_test scaled:(600, 1, 40, 98), y_test:(600,)\n",
      "\n",
      "saved to via_wav2vec_preprocess\\3.npy\n",
      " Processed 480/480 waveformsmsX_train scaled:(2400, 1, 40, 98), y_train:(2400,)\n",
      "X_test scaled:(480, 1, 40, 98), y_test:(480,)\n",
      "\n",
      "saved to via_wav2vec_preprocess\\4.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "import os\n",
    "\n",
    "save_dir = 'via_wav2vec'\n",
    "preprocess_dir = 'via_wav2vec_preprocess'\n",
    "os.makedirs(preprocess_dir, exist_ok=True)\n",
    "\n",
    "dataset_1d = []\n",
    "for fold in range(5):\n",
    "    filename = os.path.join(save_dir, str(fold)+'.npy')\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        X_train = np.load(f)\n",
    "        y_train = np.load(f)\n",
    "        X_test = np.load(f)\n",
    "        y_test = np.load(f)\n",
    "    \n",
    "    features_train = get_features(X_train)\n",
    "    features_test = get_features(X_test)\n",
    "#     print(f'\\nMFCC features shape: {len(features_train)}, {len(y_train)} {len(features_test)}, {len(y_test)}')\n",
    "    \n",
    "    X_train = np.expand_dims(features_train,1)\n",
    "    X_test = np.expand_dims(features_test,1)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "#     print(f'Shape of 4D feature array for input tensor: {X_train.shape} train, {X_test.shape} test')\n",
    "#     print(f'Shape of emotion labels: {y_train.shape} train, {y_test.shape} test')\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = feature_scaling(X_train, X_test, y_train, y_test)\n",
    "    print(f'X_train scaled:{X_train.shape}, y_train:{y_train.shape}')\n",
    "    print(f'X_test scaled:{X_test.shape}, y_test:{y_test.shape}')\n",
    "    \n",
    "    prepcoess_filename = os.path.join(preprocess_dir, str(fold)+'.npy')\n",
    "    with open(prepcoess_filename, 'wb') as f:\n",
    "        np.save(f, X_train)\n",
    "        np.save(f, y_train)\n",
    "        np.save(f, X_test)\n",
    "        np.save(f, y_test)\n",
    "    \n",
    "    print(f'\\nsaved to {prepcoess_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbdb0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
