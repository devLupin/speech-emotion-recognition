{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969eda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from natsort import natsorted\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff36aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_RAVDESS_DS(path_audios):\n",
    "    wav_paths, emotions, actors = [], [], []\n",
    "    for path in tqdm(Path(path_audios).glob(\"*/*.wav\")):\n",
    "        name = str(path).split('/')[-1].split('.')[0]\n",
    "        label = int(name.split(\"-\")[2]) - 1  # Start emotions in 0\n",
    "        actor = int(name.split(\"-\")[-1])\n",
    "\n",
    "        try:\n",
    "            wav_paths.append(path)\n",
    "            emotions.append(label)\n",
    "            actors.append(actor)\n",
    "        except Exception as e:\n",
    "            # print(str(path), e)\n",
    "            pass\n",
    "        \n",
    "    return wav_paths, emotions, actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd9c90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1440it [00:00, 72000.07it/s]\n"
     ]
    }
   ],
   "source": [
    "paths, emotions, actors = prepare_RAVDESS_DS('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b5bec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "\n",
    "augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "    Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b80a0cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = []\n",
    "def size_check(paths):\n",
    "    \n",
    "    for i, path in tqdm(enumerate(paths), desc='melspectrogram image generate.....'):\n",
    "        y, sr = librosa.load(path, sr=16000)\n",
    "        augmented_y = augment(samples=y, sample_rate=16000)\n",
    "        \n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, win_length=512, window='hamming', hop_length=256, n_mels=256, fmax=sr/2)\n",
    "        melspectrogram = librosa.power_to_db(S, ref=np.max)\n",
    "        \n",
    "        S_aug = librosa.feature.melspectrogram(y=augmented_y, sr=sr, n_fft=1024, win_length=512, window='hamming', hop_length=256, n_mels=256, fmax=sr/2)\n",
    "        melspectrogram_aug = librosa.power_to_db(S_aug, ref=np.max)\n",
    "        \n",
    "        sz.append(max(melspectrogram.shape[1], melspectrogram_aug.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa130247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 1440it [02:46,  8.64it/s]\n"
     ]
    }
   ],
   "source": [
    "size_check(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48dc2e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_melspectrogram(paths, emotions, actors, sz):\n",
    "    data = []\n",
    "    data_aug = []\n",
    "    for i, path in tqdm(enumerate(paths), desc='melspectrogram image generate.....'):\n",
    "        y, sr = librosa.load(path, sr=16000)\n",
    "        augmented_y = augment(samples=y, sample_rate=16000)\n",
    "        \n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, win_length=512, window='hamming', hop_length=256, n_mels=256, fmax=sr/2)\n",
    "        melspectrogram = librosa.power_to_db(S, ref=np.max)\n",
    "        \n",
    "        S_aug = librosa.feature.melspectrogram(y=augmented_y, sr=sr, n_fft=1024, win_length=512, window='hamming', hop_length=256, n_mels=256, fmax=sr/2)\n",
    "        melspectrogram_aug = librosa.power_to_db(S_aug, ref=np.max)\n",
    "        \n",
    "        origin = np.zeros((256, sz))\n",
    "        origin[:, :melspectrogram.shape[1]] = melspectrogram\n",
    "        \n",
    "        aug = np.zeros((256, sz))\n",
    "        aug[:, :melspectrogram_aug.shape[1]] = melspectrogram_aug\n",
    "        \n",
    "        data.append({\n",
    "            'melspectrogram_feature': origin,\n",
    "            'emotion': emotions[i],\n",
    "            'actor': actors[i]\n",
    "        })\n",
    "        \n",
    "        data_aug.append({\n",
    "            'melspectrogram_feature': origin,\n",
    "            'emotion': emotions[i],\n",
    "            'actor': actors[i]\n",
    "        })\n",
    "        data_aug.append({\n",
    "            'melspectrogram_feature': aug,\n",
    "            'emotion': emotions[i],\n",
    "            'actor': actors[i]\n",
    "        })\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    df_aug = pd.DataFrame(data_aug)\n",
    "    return df, df_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b31907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "melspectrogram image generate.....: 1440it [02:42,  8.84it/s]\n"
     ]
    }
   ],
   "source": [
    "df, df_aug = save_melspectrogram(paths, emotions, actors, max(sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d8b15c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.functional import compute_deltas\n",
    "import torch\n",
    "\n",
    "def get_deltas(feature):\n",
    "    f = np.expand_dims(feature, 1)\n",
    "    f = torch.Tensor(f)\n",
    "    \n",
    "    delta = compute_deltas(f)\n",
    "    delta2 = compute_deltas(delta)\n",
    "    \n",
    "    ret = torch.cat([f, delta, delta2], dim=1)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61b75f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test(fold, df, df_aug, save_path=\"\"):\n",
    "    \"\"\"\n",
    "    Divide the data in train and test in a subject-wise 5-CV way. The division is generated before running the training\n",
    "    of each fold.\n",
    "    :param fold:[int] Fold to create the train and test sets [ranging from 0 - 4]\n",
    "    :param df:[DataFrame] Dataframe with the complete list of files generated\n",
    "    :param save_path:[str] Path to save the train.csv and test.csv per fold\n",
    "    \"\"\"\n",
    "    \n",
    "    actors_per_fold = {\n",
    "        0: [2,5,14,15,16],\n",
    "        1: [3, 6, 7, 13, 18],\n",
    "        2: [10, 11, 12, 19, 20],\n",
    "        3: [8, 17, 21, 23, 24],\n",
    "        4: [1, 4, 9, 22],\n",
    "    }\n",
    "\n",
    "    test_df = df.loc[df['actor'].isin(actors_per_fold[fold])]\n",
    "    train_df = df_aug.loc[~df_aug['actor'].isin(actors_per_fold[fold])]\n",
    "\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    \n",
    "    X_train = np.array([data for data in train_df['melspectrogram_feature']])\n",
    "    y_train = np.array([data for data in train_df['emotion']])\n",
    "    X_test = np.array([data for data in test_df['melspectrogram_feature']])\n",
    "    y_test = np.array([data for data in test_df['emotion']])\n",
    "    \n",
    "    X_train = get_deltas(X_train)\n",
    "    X_test = get_deltas(X_test)\n",
    "    \n",
    "    with open(save_path+'.npy', 'wb') as f:\n",
    "        np.save(f, X_train)\n",
    "        np.save(f, y_train)\n",
    "        np.save(f, X_test)\n",
    "        np.save(f, y_test)\n",
    "        \n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1ce940d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2280, 3, 256, 330]) (2280,) torch.Size([300, 3, 256, 330]) (300,)\n",
      "torch.Size([2280, 3, 256, 330]) (2280,) torch.Size([300, 3, 256, 330]) (300,)\n",
      "torch.Size([2280, 3, 256, 330]) (2280,) torch.Size([300, 3, 256, 330]) (300,)\n",
      "torch.Size([2280, 3, 256, 330]) (2280,) torch.Size([300, 3, 256, 330]) (300,)\n",
      "torch.Size([2400, 3, 256, 330]) (2400,) torch.Size([240, 3, 256, 330]) (240,)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for fold in range(5):\n",
    "    \n",
    "    save_path = os.path.join('5-CV-augment', \"fold\"+str(fold))\n",
    "    \n",
    "    generate_train_test(fold, df, df_aug, save_path)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21536b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5be54bb8ddc52e76cc18bd1012223019b9a180863a571d33caf1c2c34a734fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
